<p>

  Sound in real life originates from a single point and spreads in a sphere from the origin, where Unity’s sound system works in the same way. As we fully want to seize the capabilities that AR (Augmented Reality) offers, we want to stray away from how we’re used to perceive these modalities in real life and instead focus on how we can enhance them in AR.

  We wanted a ‘laser sound’ to travel along the line renderer of the raycast - that is our laser. In real life a laser wouldn’t emit sound, but we thought it would enhance our game if our did. So by rethinking sound and how it originates, we have created an <strong>adaptive 3D sound system</strong> from scratch. The system could be called a ‘volumetric’ sound system, as it functionally works in the same way. But instead of making a whole volume emit sound we make the point sound adapt along the player’s position. 

</p>


<iframe src="https://giphy.com/embed/QmJ3s6QZwvJHTrm4DW" width="480" height="270" frameBorder="0" class="giphy-embed" allowFullScreen></iframe>

<p>
  By adding this adaptive 3D sound system along with other auditory and haptic feedback, our game can rely less on visual feedback while embracing the multimodal interactions.

</p>
<img src="img/jonas_100.png">
<p>Signed Jonas Abu Nijmeh</p>
